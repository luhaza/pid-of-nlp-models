{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the classification accuracy of BERT, BART, GPT, Llama models (which are politically leaning) on text classification accuracy of politically biased statements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'sentence', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/IBC/sample_ibc.csv\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cs375/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: 54\n",
      "Total sentences: 150\n",
      "Accuracy: 36.00%\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# bart\n",
    "pipe = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "political_labels = [\"Liberal\", \"Conservative\", \"Neutral\"]\n",
    "\n",
    "def classify_sentence(sentence):\n",
    "    result = pipe(sentence, candidate_labels=political_labels)\n",
    "    top_label = result[\"labels\"][0]\n",
    "    return top_label\n",
    "\n",
    "df[\"predicted_label\"] = df[\"sentence\"].apply(classify_sentence)\n",
    "\n",
    "correct_predictions = (df[\"predicted_label\"] == df[\"label\"]).sum()\n",
    "\n",
    "total_sentences = len(df)\n",
    "accuracy = correct_predictions / total_sentences\n",
    "\n",
    "print(f\"Correct predictions: {correct_predictions}\")\n",
    "print(f\"Total sentences: {total_sentences}\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cs375/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/cs375/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions: 59\n",
      "Total sentences: 150\n",
      "Accuracy: 39.33%\n"
     ]
    }
   ],
   "source": [
    "# roberta and deberta, deberta out-performs roberta\n",
    "# cross-encoder/nli-deberta-v3-base\n",
    "from transformers import pipeline\n",
    "\n",
    "# bert\n",
    "pipe = pipeline(model=\"cross-encoder/nli-deberta-v3-base\")\n",
    "\n",
    "political_labels = [\"Liberal\", \"Conservative\", \"Neutral\"]\n",
    "\n",
    "def classify_sentence(sentence):\n",
    "    result = pipe(sentence, candidate_labels=political_labels)\n",
    "    top_label = result[\"labels\"][0]\n",
    "    return top_label\n",
    "\n",
    "df[\"predicted_label\"] = df[\"sentence\"].apply(classify_sentence)\n",
    "\n",
    "correct_predictions = (df[\"predicted_label\"] == df[\"label\"]).sum()\n",
    "\n",
    "total_sentences = len(df)\n",
    "accuracy = correct_predictions / total_sentences\n",
    "\n",
    "print(f\"Correct predictions: {correct_predictions}\")\n",
    "print(f\"Total sentences: {total_sentences}\")\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs375",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
