{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DeBERTa Zero Shot Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "data_path = os.path.abspath(os.path.join(os.getcwd(), '../../data'))\n",
    "sys.path.append(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import sample, evaluation\n",
    "deberta1 = evaluation.copy()\n",
    "deberta2 = evaluation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_labels = [\"Liberal\", \"Conservative\", \"Neutral\"]\n",
    "political_labels_n = [\"Liberal\", \"Conservative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cs375/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/cs375/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# roberta and deberta, deberta out-performs roberta\n",
    "# cross-encoder/nli-deberta-v3-base\n",
    "\n",
    "# bert\n",
    "pipe1 = pipeline(model=\"cross-encoder/nli-deberta-v3-base\")\n",
    "\n",
    "def classify_sentence(sentence):\n",
    "    result = pipe1(sentence, candidate_labels=political_labels)\n",
    "    top_label = result[\"labels\"][0]\n",
    "    return top_label\n",
    "\n",
    "deberta1[\"predicted_label\"] = deberta1[\"sentence\"].apply(classify_sentence)\n",
    "\n",
    "label_counts_deberta1 = deberta1[\"predicted_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cs375/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/cs375/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe2 = pipeline(model=\"cross-encoder/nli-deberta-v3-base\")\n",
    "\n",
    "def classify_sentence(sentence):\n",
    "    result = pipe2(sentence, candidate_labels=political_labels_n)\n",
    "    top_label = result[\"labels\"][0]\n",
    "    return top_label\n",
    "\n",
    "deberta2[\"predicted_label\"] = deberta2[\"sentence\"].apply(classify_sentence)\n",
    "\n",
    "label_counts_deberta2 = deberta2[\"predicted_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_label\n",
      "Neutral         305\n",
      "Conservative    302\n",
      "Liberal         143\n",
      "Name: count, dtype: int64 predicted_label\n",
      "Conservative    513\n",
      "Liberal         237\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(label_counts_deberta1, label_counts_deberta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Conservative    134\n",
       "Liberal          63\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta_correct = deberta1[deberta1[\"label\"] == deberta1[\"predicted_label\"]]\n",
    "deberta_correct.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Finetuned BERT base model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from data import sample_dataset, evaluation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on same sample dataset\n",
    "infer_tokenizer = AutoTokenizer.from_pretrained(\"lhz1/pid-ft-bert\")\n",
    "ft_model = AutoModelForSequenceClassification.from_pretrained(\"lhz1/pid-ft-bert\")\n",
    "\n",
    "\n",
    "def run_model(dataset):\n",
    "    predictions = []\n",
    "    accurate = 0\n",
    "    for example in dataset:\n",
    "        inputs = infer_tokenizer(example[\"sentence\"], return_tensors=\"pt\")\n",
    "        label = example[\"label\"]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = ft_model(**inputs).logits\n",
    "\n",
    "            predicted_class_id = logits.argmax().item()\n",
    "            if predicted_class_id == label: accurate += 1\n",
    "            predictions.append((ft_model.config.id2label[predicted_class_id], label == predicted_class_id))\n",
    "\n",
    "    return predictions, accurate / len(sample_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           \n",
       "Conservative    82\n",
       "Liberal         36\n",
       "Neutral         32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample dataset\n",
    "preds = run_model(sample_dataset)\n",
    "pred_labels = pd.DataFrame(data=preds[0])\n",
    "acc = preds[1]\n",
    "\n",
    "pred_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             1    \n",
       "Conservative  True     270\n",
       "              False    204\n",
       "Liberal       True     142\n",
       "              False     74\n",
       "Neutral       False     60\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#larger (n=750) with no neutral examples\n",
    "preds2 = run_model(evaluation_dataset)\n",
    "pred_labels2 = pd.DataFrame(data=preds2[0])\n",
    "acc2 = preds2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "Conservative    270\n",
       "Liberal         142\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_correct = pred_labels2[pred_labels2[1] == True]\n",
    "bert_correct[0].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs375",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
